{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9491137793024585\n",
      "[[344   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0 306   5   5   1   0   0  40   0   5   0]\n",
      " [  0  56 359   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0 326   0   6   0   0   0   0   0]\n",
      " [  0   1   0   0 355   0   0   0   0   0   0]\n",
      " [  0   0   0   0   8 319   3   1   3   0   0]\n",
      " [  0   0   0   0   0   0 329   0   0   0   0]\n",
      " [  0   0   0   3   0   0   0 320   0   1   0]\n",
      " [ 19   1   0   0   0   0   4   1 333   1   0]\n",
      " [  0   0   0   2   0  10   0   2   0 329   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      1.00      0.97       344\n",
      "         1.0       0.84      0.85      0.84       362\n",
      "         2.0       0.99      0.87      0.92       415\n",
      "         3.0       0.97      0.98      0.98       332\n",
      "         4.0       0.98      1.00      0.99       356\n",
      "         5.0       0.95      0.96      0.95       334\n",
      "         6.0       0.98      1.00      0.99       329\n",
      "         7.0       0.88      0.99      0.93       324\n",
      "         8.0       0.99      0.93      0.96       359\n",
      "         9.0       0.98      0.96      0.97       343\n",
      "\n",
      "    accuracy                           0.95      3498\n",
      "   macro avg       0.95      0.95      0.95      3498\n",
      "weighted avg       0.95      0.95      0.95      3498\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Program Files\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:71: FutureWarning: Pass labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import minmax_scale\n",
    "import numpy as np\n",
    "import sklearn as sk\n",
    "from sklearn import covariance\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "\n",
    "def multivariate_normal(x, d, mean, covariance):\n",
    "    \"\"\"pdf of the multivariate normal distribution.\"\"\"\n",
    "    x_m = x - mean\n",
    "    return (1. / (np.sqrt((2 * np.pi)**d * np.linalg.det(covariance))) * \n",
    "            np.exp(-(np.linalg.solve(covariance, x_m).T.dot(x_m)) / 2))\n",
    "\n",
    "\n",
    "trainData = pd.read_csv('pendigitstrain.csv')\n",
    "testData = pd.read_csv('pendigitstest.csv')\n",
    "\n",
    "TrainLabel = trainData['17']\n",
    "TestLabel = testData['17']\n",
    "\n",
    "TrainFeat = trainData.drop(['17'],axis = 1)\n",
    "TestFeat = testData.drop(['17'],axis = 1)\n",
    "\n",
    "TrainFeatScaled = minmax_scale(TrainFeat, feature_range = (0,1))\n",
    "TestFeatScaled = minmax_scale(TestFeat, feature_range = (0,1))\n",
    "\n",
    "\n",
    "def decision(x, X, Y):\n",
    "    probability_List = []\n",
    "    num_classes = len(np.unique(Y))\n",
    "    shrinkage = 0.15\n",
    "    Lambda_r = 0.8\n",
    "    Lambda_s = 1\n",
    "    P_UnD = 1-(Lambda_r/Lambda_s)\n",
    "    N_T = len(X)\n",
    "    for i in range(num_classes):\n",
    "        X_train = X[Y==i]\n",
    "        mean = X_train.mean(axis=0)\n",
    "        cov = np.cov(X_train,rowvar=False)\n",
    "        newcov = sk.covariance.shrunk_covariance(cov, shrinkage=shrinkage)\n",
    "#         var = multivariate_normal(mean=mean, cov=newcov)\n",
    "        probability = multivariate_normal(x, len(x), mean, newcov)*(len(X_train)/N_T)\n",
    "        probability_List.append(probability)\n",
    "    \n",
    "    p = 0\n",
    "    for i in probability_List:\n",
    "        p = p+i\n",
    "        \n",
    "    if max(probability_List)>= P_UnD*p:\n",
    "        return probability_List.index(max(probability_List))\n",
    "    else:\n",
    "        return len(probability_List)  \n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "TestDecision = np.zeros((len(TestLabel),1))\n",
    "CCR = 0\n",
    "for i in range(len(TestDecision)):\n",
    "    x = TestFeatScaled[i][:]\n",
    "    TestDecision[i][0]=decision(x, TrainFeatScaled, TrainLabel)\n",
    "    if TestDecision[i][0] == TestLabel[i]:\n",
    "        CCR += 1\n",
    "        \n",
    "print(CCR/len(TestLabel))\n",
    "print(confusion_matrix(TestDecision, TestLabel, [0, 1,2,3,4,5,6,7,8,9,10]))\n",
    "print(classification_report(TestDecision, TestLabel))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
